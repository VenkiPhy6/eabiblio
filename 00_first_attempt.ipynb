{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15fd4bca",
   "metadata": {},
   "source": [
    "# How 'rigorous' is the philosophy literature on Effective Altruism (EA)?\n",
    "\n",
    "A first college try\n",
    "\n",
    "Aug 14, 2025\n",
    "\n",
    "[I made a comment in a forum](https://forum.effectivealtruism.org/posts/d4qcWisHZA2XtASJX/the-effective-altruism-community-inherits-the-problems-of?commentId=zeK94LfySZo7jWxCC) supporting the claim that Effective Altruism (EA) philsophy literature lacks rigor due to insularity. Someone made a wonderful counter saying EA literature is published in top philosophy journals which makes my claim suspect. I thought, \"Oh snap! Thats it! Thats the empirical angle here! Why didn't I think of this first? The OP literally had charts and I should've made my own.\" And thus we are here. I want to assess the feasibility of a project to measure how good Effective Altruism is in the context of the rest of philosophy and academic lit as a whole. It should probably also measure something like \"interdisciplinarity\" because that is the part I am mostly critical about. \n",
    "\n",
    "Keep all that aside for now because it requires some litrev legwork. before doing that work, lets just look for papers with \"Effective Altruism\" in the title+abstract and see if something is even there to do worthwile work here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180b9aba",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "I am going to use [OpenAlex](https://openalex.org/) because I am using it for another project, and I have already done the legwork to create a local version of the whole database in my dept's server (See [my other repo](https://github.com/VenkiPhy6/oalexdump) if you want to create a local version for yourself). The [OpenAlex website](https://help.openalex.org/hc/en-us/articles/24396686889751-About-us) describes the dataset as \"...a catalog of works. A work is any sort of scholarly output. A research article is one kind of work, but there are others such as datasets, books, and dissertations. We keep track of these worksâ€”their titles (and abstracts and full text in many cases), when they were created, etc. But that's not all we do. We also keep track of the connections between these works, finding associations through things like journals, authors, institutional affiliations, citations, concepts, and funders. ...\" So it contains research across all disciplines. The website also lists their sources - \"Currently (as of January 2025), the list of core sources we pull this type of information includes Crossref, DataCite, PubMed, HAL, DOAJ, ORCID, MAG, arXiv, Dergipark, OSTI, RePEc, UNC Carolina, University of Michigan Deep Blue, Zenodo, ISSN, other institutional repositories (full list), parsing of 60M open access PDFs, some journal landing pages, directly from some publishers, and from our users through community curation requests. We're working on a significant rewrite to the OpenAlex guts code that will enable us to add many new core sources starting in March 2025.\" I hope that gives you an idea of what is in this dataset. They are open source and have their code up on [this repository](https://github.com/ourresearch) but I haven't read any of it.\n",
    "\n",
    "The other neat thing about OpenAlex is the ML classification of topics of those scholarly outputs. You can read more about it on [the OpenAlex docs](https://docs.openalex.org/api-entities/topics). From what I've heard this is a good starting point, but of course you'd need to do some of your stuff. LLMs are cheap in 2025 and so this shouldn't stand in the way. From personal experience one thing that I know is bad is the institutional affiliations. I know that the institution strings are untidy but its not uncleanable. In a sample I was focussing on, I saw that the fill rate of institutional affiliations was also bad but that may not be true in general.\n",
    "\n",
    "Throughout the rest of the code, I will be using a local version of the database that I have on my machine. But it is also available via [the OpenAlex API](https://docs.openalex.org/how-to-use-the-api/api-overview). It should be possible for you to 'mostly' replicate the numbers I provide below. I say 'mostly' because I loaded the data in December 2024 and haven't updated. So if there are newer publications since Jan 2025 I may have missed those. But I don't think there was a seismic shift in EA lit during that time and so the results shouldn't change substantively even if you use the API to pull the latest data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac58b889",
   "metadata": {},
   "source": [
    "## Method\n",
    "\n",
    "With the dataset and a motivation clear, what do I want to check here? The big question is - what is the comparison group/coutnerfactual? So EA is less rigourous and less interdisciplinary compared to what exactly? What is a worthwhile comparison here? The OP in the forum post compares it to Econ but is that right? This is question I have to wrestle with throughout this project. Lets start somewhere and see what pops up in a first go as a comparison group\n",
    "\n",
    "I think implicitly in my rant, I belive that it is less rigorours compared to other philosophy owing to its lack of interdisciplinarity. So at a construct level treatment is something like \"Being an a paper in philosophy X\". Outcomes are \"Interdisciplinarity\" and \"Rigor\". As a first operationalization lets say treatment is 1 if paper contains the phrase \"effective altruism\" in title/abstract. Then say treatment is 0 if that phrase isn't there but there is a paper in the same OpenAlex topics as those papers that contain that phrase. For now I will not operationalize \"Interdisciplinarity\" and \"Rigor\" since it requires some important litrev legwork.\n",
    "\n",
    "With that clear lets go ahead, make some plots and check feasibility of the treatment measure here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85ec2bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import duckdb\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803c4fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\o'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\o'\n",
      "C:\\Users\\vxs210125\\AppData\\Local\\Temp\\ipykernel_14272\\2210588090.py:2: SyntaxWarning: invalid escape sequence '\\o'\n",
      "  oalex_csv_dir = \"D:\\oalexdump\\csv_files\"\n",
      "C:\\Users\\vxs210125\\AppData\\Local\\Temp\\ipykernel_14272\\2210588090.py:2: SyntaxWarning: invalid escape sequence '\\o'\n",
      "  oalex_csv_dir = \"D:\\oalexdump\\csv_files\"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Query interrupted",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m con  = duckdb.connect(\u001b[33m\"\u001b[39m\u001b[33m./data/eapubs.duckdb\u001b[39m\u001b[33m\"\u001b[39m, read_only=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      2\u001b[39m oalex_csv_dir = \u001b[33m\"\u001b[39m\u001b[33mD:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33moalexdump\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mcsv_files\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mcon\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m      4\u001b[39m \u001b[33;43m        CREATE TABLE eapubs as \u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[33;43m        SELECT * FROM read_csv_auto(\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moalex_csv_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mworks.csv.gz\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[33;43m)\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[33;43m        WHERE LOWER(title) LIKE \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m%effective altrusim%\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m OR LOWER(abstract_inverted_index) LIKE \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m%altruism%\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m OR LOWER(abstract_inverted_index) LIKE \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m%effective%\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[33;43m        ;\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[33;43m        \u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Query interrupted"
     ]
    }
   ],
   "source": [
    "con  = duckdb.connect(\"./data/eabiblio.duckdb\", read_only=False)\n",
    "oalex_csv_dir = \"D:\\oalexdump\\csv_files\"\n",
    "con.sql(f\"\"\"\n",
    "        CREATE TABLE eapubs as \n",
    "        SELECT * FROM read_csv_auto('{join(oalex_csv_dir, 'works.csv.gz')}')\n",
    "        WHERE LOWER(title) LIKE '%effective altrusim%' OR LOWER(abstract_inverted_index) LIKE '%effective%altruism%'\n",
    "        ;\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58490204",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interdisci (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
